{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sQk-CC29AL0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE \n",
        "from sklearn.decomposition import PCA \n",
        "pd.set_option('display.max_columns', None)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "NUXM8kMYqiQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "data = pd.read_excel(io.BytesIO(uploaded.get('Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')))"
      ],
      "metadata": {
        "id": "yqxSwV2NqiQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "id": "ytyXbz_IqiQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Pre-Processing\n",
        "print(data.dtypes)\n",
        "data.select_dtypes(object)"
      ],
      "metadata": {
        "id": "qGST-EC0qiQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "without_ICU_column = data.drop('ICU', axis = 1)       #seperating the ICU lable column\n",
        "ICU_column = data['ICU']\n",
        "colums_to_convert = data.select_dtypes(object).columns   #finding columns that are not of type float or int\n",
        "colums_to_convert"
      ],
      "metadata": {
        "id": "SYc0XCoMqiQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "without_ICU_column = pd.get_dummies(without_ICU_column, columns = colums_to_convert)      #performing hotcoding\n",
        "without_ICU_column.head()"
      ],
      "metadata": {
        "id": "-G1SCNFOqiQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_expand = pd.concat([without_ICU_column, ICU_column], axis = 1)         #adding the ICU column again at the last position\n",
        "data_expand.head(5)"
      ],
      "metadata": {
        "id": "FJ5Y3swBqiQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = data_expand.columns\n",
        "arr = data_expand.to_numpy()\n",
        "print(arr)\n",
        "i=0\n",
        "ICU_admitted_rows = []\n",
        "while(i<len(arr)):            #loop to record the rows in which patient is admitted to the ICU and adding 1 label to the previous rows.\n",
        "  for j in range(5):\n",
        "    if(arr[i+j][-1]==1):\n",
        "      for k in range(j):\n",
        "        arr[i+k][-1]=1\n",
        "      for toremove in range(i+j,i+5):\n",
        "        ICU_admitted_rows.append(toremove)\n",
        "      break\n",
        "  i+=5\n",
        "print(ICU_admitted_rows)\n",
        "deletedcount = 0\n",
        "for rowToRemove in ICU_admitted_rows:             #removing the rows in which patient was admitted to the ICU\n",
        "  arr = np.delete(arr, rowToRemove-deletedcount, axis=0)\n",
        "  deletedcount+=1\n",
        "df = pd.DataFrame(arr, columns = column_names)"
      ],
      "metadata": {
        "id": "JpiZ0VS1qiQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling missing values\n",
        "pd.options.mode.chained_assignment = None \n",
        "edited_dfs_list = []\n",
        "max_patient_id = df['PATIENT_VISIT_IDENTIFIER'].max()\n",
        "for i in range(int(max_patient_id)):                      #keeping only the first window that is 0-2 for every patient and filling NaN values with mean of all windows\n",
        "  tempdf = df[df['PATIENT_VISIT_IDENTIFIER']==i]\n",
        "  if(len(tempdf)!=0):\n",
        "    tempdf.fillna(tempdf.mean(), inplace=True)\n",
        "    tempdf = tempdf.iloc[[0]]\n",
        "    edited_dfs_list.append(tempdf)\n",
        "\n",
        "  \n",
        "final_data = pd.concat(edited_dfs_list)\n",
        "final_data.head(30)"
      ],
      "metadata": {
        "id": "MVLNaZCeqiQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = final_data.drop(['GENDER','PATIENT_VISIT_IDENTIFIER','WINDOW_0-2',\t'WINDOW_2-4',\t'WINDOW_4-6',\t'WINDOW_6-12',\t'WINDOW_ABOVE_12'],axis = 1)\n",
        "final_data.head()"
      ],
      "metadata": {
        "id": "JWCuhCzwqiQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.describe()"
      ],
      "metadata": {
        "id": "_lvMywkgqiQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = final_data.dropna(axis = 0)  "
      ],
      "metadata": {
        "id": "skQkLfspqiQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ypEWkfutEQ07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis (EDA) "
      ],
      "metadata": {
        "id": "VScXACwtD-zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Analysis Visualising the pre preoessed data and trying to get the intution about different characterstics."
      ],
      "metadata": {
        "id": "BIekIUEXqiQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.describe()"
      ],
      "metadata": {
        "id": "2mcwLAEGqiQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ICU_admission_distribution = final_data['ICU'].value_counts()\n",
        "print(\"Total Patients after pre processing: \", sum(ICU_admission_distribution))\n",
        "print(\"Distribution of ICU admissions\")\n",
        "print(\"Patients who were not admitted to ICU: \",ICU_admission_distribution[0])\n",
        "print(\"Patients who were admitted to ICU: \",ICU_admission_distribution[1])\n",
        "labels= ['Admitted to ICU', 'Not Admitted to ICU']\n",
        "colors=['tomato', 'deepskyblue']\n",
        "sizes= [ICU_admission_distribution[1], ICU_admission_distribution[0]]\n",
        "plt.pie(sizes,labels=labels, colors=colors, startangle=100, autopct='%1.1f%%')\n",
        "plt.title(\"ICU Distribution of data\")\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZCWEaY0fqiQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Age_distribution = final_data['AGE_ABOVE65'].value_counts()\n",
        "print(\"Age Distribution\")\n",
        "print(\"Patients below age 65: \",Age_distribution[0])\n",
        "print(\"Patients above age 65: \",Age_distribution[1])\n",
        "labels= ['Below 65', 'Above 65']\n",
        "colors=['lightgreen', 'violet']\n",
        "sizes= [Age_distribution[0], Age_distribution[1]]\n",
        "plt.pie(sizes,labels=labels, colors=colors, startangle=90, autopct='%1.1f%%')\n",
        "plt.axis('equal')\n",
        "plt.title(\"Age Distribution of data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0ufcz_38qiQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ICU_Admitted_data = final_data[final_data['ICU']==1]\n",
        "Age_distribution = ICU_Admitted_data['AGE_ABOVE65'].value_counts()\n",
        "print(\"Age Distribution\")\n",
        "print(\"Patients below age 65: \",Age_distribution[0])\n",
        "print(\"Patients above age 65: \",Age_distribution[1])\n",
        "labels= ['Below 65', 'Above 65']\n",
        "colors=['orange', 'cyan']\n",
        "sizes= [Age_distribution[0], Age_distribution[1]]\n",
        "plt.pie(sizes,labels=labels, colors=colors, startangle=90, autopct='%1.1f%%')\n",
        "plt.axis('equal')\n",
        "plt.title(\"Age Distribution of ICU Admitted patients\")\n",
        "plt.show()\n",
        "\n",
        "x = [[],[]]\n",
        "x[0].append(final_data['AGE_PERCENTIL_10th'].value_counts()[1])\n",
        "x[0].append(final_data['AGE_PERCENTIL_20th'].value_counts()[1])\n",
        "x[0].append(final_data['AGE_PERCENTIL_30th'].value_counts()[1])\n",
        "x[0].append(final_data['AGE_PERCENTIL_40th'].value_counts()[1])\n",
        "x[0].append(final_data['AGE_PERCENTIL_50th'].value_counts()[1])\n",
        "x[0].append(final_data['AGE_PERCENTIL_60th'].value_counts()[1])\n",
        "x[0].append(final_data['AGE_PERCENTIL_70th'].value_counts()[1])\n",
        "x[0].append(final_data['AGE_PERCENTIL_80th'].value_counts()[1])\n",
        "x[0].append(final_data['AGE_PERCENTIL_90th'].value_counts()[1])\n",
        "x[0].append(final_data['AGE_PERCENTIL_Above 90th'].value_counts()[1])\n",
        "\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_10th'].value_counts()[1])\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_20th'].value_counts()[1])\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_30th'].value_counts()[1])\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_40th'].value_counts()[1])\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_50th'].value_counts()[1])\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_60th'].value_counts()[1])\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_70th'].value_counts()[1])\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_80th'].value_counts()[1])\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_90th'].value_counts()[1])\n",
        "x[1].append(ICU_Admitted_data['AGE_PERCENTIL_Above 90th'].value_counts()[1])\n",
        "\n",
        "a = []\n",
        "c=1\n",
        "for i in x[0]:\n",
        "  a.extend([c*10]*i)\n",
        "  c+=1\n",
        "plt.hist(a, 20, label='Total')\n",
        "b = []\n",
        "c=1\n",
        "for i in x[1]:\n",
        "  b.extend([c*10]*i)\n",
        "  c+=1\n",
        "print(x)\n",
        "plt.hist(b, 20, label='ICU Admitted')\n",
        "plt.xticks([10,20,30,40,50,60,70,80,90,100],['AGE_PERCENTIL_10th','AGE_PERCENTIL_20th','AGE_PERCENTIL_30th','AGE_PERCENTIL_40th','AGE_PERCENTIL_50th','AGE_PERCENTIL_60th','AGE_PERCENTIL_70th','AGE_PERCENTIL_80th','AGE_PERCENTIL_90th','AGE_PERCENTIL_Above 90'], rotation = 70)\n",
        "plt.legend()\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Age Distribution Total and ICU Admitted')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0VsQdAgYqiQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Diesease_Grouping_1 = final_data['DISEASE GROUPING 1'].value_counts()\n",
        "Diesease_Grouping_2 = final_data['DISEASE GROUPING 2'].value_counts()\n",
        "Diesease_Grouping_3 = final_data['DISEASE GROUPING 3'].value_counts()\n",
        "Diesease_Grouping_4 = final_data['DISEASE GROUPING 4'].value_counts()\n",
        "Diesease_Grouping_5 = final_data['DISEASE GROUPING 5'].value_counts()\n",
        "Diesease_Grouping_6 = final_data['DISEASE GROUPING 6'].value_counts()\n",
        "HTN_total = final_data['HTN'].value_counts()\n",
        "Immunocompromised_total = final_data['IMMUNOCOMPROMISED'].value_counts()\n",
        "Other_total = final_data['OTHER'].value_counts()\n",
        "\n",
        "ICU_Diesease_Grouping_1 = ICU_Admitted_data['DISEASE GROUPING 1'].value_counts()\n",
        "ICU_Diesease_Grouping_2 = ICU_Admitted_data['DISEASE GROUPING 2'].value_counts()\n",
        "ICU_Diesease_Grouping_3 = ICU_Admitted_data['DISEASE GROUPING 3'].value_counts()\n",
        "ICU_Diesease_Grouping_4 = ICU_Admitted_data['DISEASE GROUPING 4'].value_counts()\n",
        "ICU_Diesease_Grouping_5 = ICU_Admitted_data['DISEASE GROUPING 5'].value_counts()\n",
        "ICU_Diesease_Grouping_6 = ICU_Admitted_data['DISEASE GROUPING 6'].value_counts()\n",
        "HTN_ICU = ICU_Admitted_data['HTN'].value_counts()\n",
        "Immunocompromised_ICU = ICU_Admitted_data['IMMUNOCOMPROMISED'].value_counts()\n",
        "Other_ICU = ICU_Admitted_data['OTHER'].value_counts()\n",
        "\n",
        "x = np.array([[Diesease_Grouping_1[1],Diesease_Grouping_2[1],Diesease_Grouping_3[1],Diesease_Grouping_4[1],Diesease_Grouping_5[1],Diesease_Grouping_6[1],HTN_total[1], Immunocompromised_total[1]],[ICU_Diesease_Grouping_1[1],ICU_Diesease_Grouping_2[1],ICU_Diesease_Grouping_3[1],ICU_Diesease_Grouping_4[1],ICU_Diesease_Grouping_5[1],ICU_Diesease_Grouping_6[1],HTN_ICU[1], Immunocompromised_ICU[1]]])\n",
        "a = []\n",
        "c=1\n",
        "for i in x[0]:\n",
        "  a.extend([c]*i)\n",
        "  c+=1\n",
        "plt.hist(a, 15, label='Total')\n",
        "b = []\n",
        "c=1\n",
        "for i in x[1]:\n",
        "  b.extend([c]*i)\n",
        "  c+=1\n",
        "print(x)\n",
        "plt.hist(b, 15, label='ICU Admitted')\n",
        "plt.xticks([1,2,3,4,5,6,7,8,9],['Diesease_Grouping_1','Diesease_Grouping_2','Diesease_Grouping_3','Diesease_Grouping_4','Diesease_Grouping_5','Diesease_Grouping_6', 'Hypertension', 'Immunocompromised'], rotation = 70)\n",
        "plt.legend()\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Disease Distribution Total and ICU Admitted')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rob2p4ysqiQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "corr = final_data.corr()\n",
        "corr.shape\n",
        "plt.subplots(figsize=(100,100))\n",
        "ax = sns.heatmap(\n",
        "    corr, \n",
        "    vmin=-1, vmax=1, center=0,\n",
        "    cmap=sns.diverging_palette(20, 220, n=200),\n",
        "    square=True\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=90,\n",
        "    horizontalalignment='right'\n",
        ");\n",
        "corr.tail()"
      ],
      "metadata": {
        "id": "zAHb3bV7qiQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr.shape\n",
        "ICU_corr = corr.iloc[236]\n",
        "ICU_corr.describe()"
      ],
      "metadata": {
        "id": "xZC_B5JBqiQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ICU_corr = np.array(ICU_corr)\n",
        "selection = []\n",
        "for i in ICU_corr:\n",
        "  if(i):\n",
        "    if(i>0.11):\n",
        "      selection.append(True)\n",
        "    elif(i<-0.12):\n",
        "      selection.append(True)\n",
        "    else:\n",
        "      selection.append(False)\n",
        "  else:\n",
        "    selection.append(False)\n",
        "\n",
        "print(len(selection), selection.count(True))\n",
        "selection = np.array(selection)\n",
        "selected_final_data = final_data.loc[:, selection]\n",
        "selected_final_data.head()\n",
        "\n",
        "selected_final_data = selected_final_data[['AGE_ABOVE65', 'DISEASE GROUPING 2', 'DISEASE GROUPING 3', 'DISEASE GROUPING 4',\n",
        "                                           'HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN' , 'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN',\n",
        "                                           'LACTATE_MEAN', 'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN', 'PC02_VENOUS_MEAN',\n",
        "                                           'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN', 'SODIUM_MEAN', 'UREA_MEAN', 'BLOODPRESSURE_DIASTOLIC_MEAN',\n",
        "                                           'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN', 'BLOODPRESSURE_SISTOLIC_MIN',\n",
        "                                           'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN', 'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX', 'BLOODPRESSURE_SISTOLIC_MAX',\n",
        "                                           'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX', 'BLOODPRESSURE_DIASTOLIC_DIFF', 'BLOODPRESSURE_SISTOLIC_DIFF', \n",
        "                                           'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF', 'OXYGEN_SATURATION_DIFF', \n",
        "                                           'AGE_PERCENTIL_10th', 'AGE_PERCENTIL_20th', 'AGE_PERCENTIL_80th', 'AGE_PERCENTIL_90th', 'ICU']]\n",
        "\n",
        "print(selected_final_data.shape)\n",
        "selected_final_data.head()"
      ],
      "metadata": {
        "id": "ZftGPfPqqiQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = selected_final_data.corr()\n",
        "corr.shape\n",
        "plt.subplots(figsize=(30,30))\n",
        "ax = sns.heatmap(\n",
        "    corr, \n",
        "    vmin=-1, vmax=1, center=0,\n",
        "    cmap=sns.diverging_palette(20, 220, n=200),\n",
        "    square=True\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=90,\n",
        "    horizontalalignment='right'\n",
        ");\n",
        "corr.tail()"
      ],
      "metadata": {
        "id": "IDjHiHFrqiQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_final_data.columns"
      ],
      "metadata": {
        "id": "PpdOqLk9qiQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Non_ICU_Admitted_data = selected_final_data[selected_final_data['ICU']==0]\n",
        "ICU_Admitted_data = selected_final_data[selected_final_data['ICU']==1]\n",
        "\n",
        "Vital_Non_ICU_Admitted_data = Non_ICU_Admitted_data[['BLOODPRESSURE_DIASTOLIC_MEAN',\n",
        "       'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN',\n",
        "       'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN',\n",
        "       'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX',\n",
        "       'BLOODPRESSURE_SISTOLIC_MAX', 'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX',\n",
        "       'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF']]\n",
        "\n",
        "Vital_ICU_Admitted_data = ICU_Admitted_data[['BLOODPRESSURE_DIASTOLIC_MEAN',\n",
        "       'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN',\n",
        "       'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN',\n",
        "       'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX',\n",
        "       'BLOODPRESSURE_SISTOLIC_MAX', 'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX',\n",
        "       'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF']]\n",
        "\n",
        "\n",
        "Lab_Non_ICU_Admitted_data = Non_ICU_Admitted_data[['HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN',\n",
        "       'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN', 'LACTATE_MEAN',\n",
        "       'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN',\n",
        "       'PC02_VENOUS_MEAN', 'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN',\n",
        "       'SODIUM_MEAN', 'UREA_MEAN']]\n",
        "Lab_ICU_Admitted_data = ICU_Admitted_data[['HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN',\n",
        "       'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN', 'LACTATE_MEAN',\n",
        "       'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN',\n",
        "       'PC02_VENOUS_MEAN', 'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN',\n",
        "       'SODIUM_MEAN', 'UREA_MEAN']]\n",
        "\n",
        "\n",
        "# set width of bar \n",
        "barWidth = 0.25\n",
        "fig = plt.subplots(figsize =(20, 10)) \n",
        "   \n",
        "vital_non_ICU = np.array(Vital_Non_ICU_Admitted_data.mean(axis=0)) \n",
        "vital_ICU = np.array(Vital_ICU_Admitted_data.mean(axis=0)) \n",
        "   \n",
        "# Set position of bar on X axis \n",
        "br1 = np.arange(len(vital_ICU)) + (barWidth*0.5)\n",
        "br2 = [x + barWidth for x in br1]  \n",
        "   \n",
        "# Make the plot \n",
        "plt.bar(br2, vital_ICU, color ='r', width = barWidth, edgecolor ='grey', label ='ICU Admitted') \n",
        "plt.bar(br1, vital_non_ICU, color ='b', width = barWidth, edgecolor ='grey', label ='NOT Admitted') \n",
        "\n",
        "   \n",
        "plt.xlabel('Features', fontweight ='bold') \n",
        "plt.ylabel('Normalized Values', fontweight ='bold') \n",
        "plt.xticks([r + barWidth for r in range(len(vital_ICU))], ['BLOODPRESSURE_DIASTOLIC_MEAN',\n",
        "       'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN',\n",
        "       'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN',\n",
        "       'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX',\n",
        "       'BLOODPRESSURE_SISTOLIC_MAX', 'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX',\n",
        "       'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF'], rotation = 90) \n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Vital Signs of Covid19 Patients\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# set width of bar \n",
        "barWidth = 0.25\n",
        "fig = plt.subplots(figsize =(20, 10)) \n",
        "   \n",
        "lab_non_ICU = np.array(Lab_Non_ICU_Admitted_data.mean(axis=0)) \n",
        "lab_ICU = np.array(Lab_ICU_Admitted_data.mean(axis=0)) \n",
        "   \n",
        "# Set position of bar on X axis \n",
        "br1 = np.arange(len(lab_ICU)) + (barWidth*0.5)\n",
        "br2 = [x + barWidth for x in br1]  \n",
        "   \n",
        "# Make the plot \n",
        "plt.bar(br2, lab_ICU, color ='r', width = barWidth, edgecolor ='grey', label ='ICU Admitted') \n",
        "plt.bar(br1, lab_non_ICU, color ='b', width = barWidth, edgecolor ='grey', label ='NOT Admitted') \n",
        "\n",
        "   \n",
        "plt.xlabel('Features', fontweight ='bold') \n",
        "plt.ylabel('Normalized Value', fontweight ='bold') \n",
        "plt.legend()\n",
        "plt.xticks([r + barWidth for r in range(len(lab_ICU))], ['HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN',\n",
        "       'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN', 'LACTATE_MEAN',\n",
        "       'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN',\n",
        "       'PC02_VENOUS_MEAN', 'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN',\n",
        "       'SODIUM_MEAN', 'UREA_MEAN'], rotation = 90) \n",
        "plt.title(\"Lab Test Results of Covid19 patients\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q2jb52CiqiQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = np.array(selected_final_data.drop(['ICU'], axis = 1))\n",
        "Y_data = np.array(selected_final_data[['ICU']])\n",
        "print(X_data.shape)\n",
        "print(Y_data.shape)\n",
        "from sklearn.decomposition import PCA \n",
        "\n",
        "labels = []\n",
        "for i in Y_data:\n",
        "  if(i[0]==0):\n",
        "    labels.append(0)\n",
        "  else:\n",
        "    labels.append(1)\n",
        "print(X_data)\n",
        "Y_data = np.array(labels)\n",
        "\n",
        "#pca = PCA(0.80)\n",
        "#X_data = pca.fit_transform(X_data)\n",
        "print(\"pca \", X_data.shape)\n",
        "model = TSNE(n_components = 2, random_state = 0) \n",
        "  \n",
        "tsne_data = model.fit_transform(X_data) \n",
        "\n",
        "\n",
        "# creating a new data frame which \n",
        "# help us in ploting the result data \n",
        "tsne_data = np.vstack((tsne_data.T, Y_data)).T \n",
        "tsne_df = pd.DataFrame(data = tsne_data, \n",
        "     columns =(\"Dim_1\", \"Dim_2\",\"label\")) \n",
        "  \n",
        "# Ploting the result of tsne \n",
        "sns.FacetGrid(tsne_df, hue =\"label\", size = 6).map( \n",
        "       plt.scatter, 'Dim_1', 'Dim_2', s = 100).add_legend() \n",
        "  \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T4DNSPcrqiQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_final_data.head()"
      ],
      "metadata": {
        "id": "NHPnbHblqiQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data)\n",
        "print(Y_data)"
      ],
      "metadata": {
        "id": "ezeWKIRaqiQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cu1m5Hf7Ff6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training and Testing using various**\n",
        "\n",
        "*   Data Preparation for ML\n",
        "\n",
        "*   ML Model Development\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ESoKR0uSqiQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn import tree\n",
        "import graphviz\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "-gvbz6BiqiQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data.shape)\n",
        "print(Y_data.shape)"
      ],
      "metadata": {
        "id": "esu8KJhdqiQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ass(y_true,y_pred):\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "  accuracy=(tp+tn)/(tp+fp+fn+tn)\n",
        "  specificity = tn/(tn+fp)\n",
        "  sensitivity=tp/(tp+fn)\n",
        "  print(\"Accuracy:\",accuracy*100)\n",
        "  print(\"Sensitivity:\",sensitivity*100)\n",
        "  print(\"Specificity:\",specificity*100)\n",
        "  print(\"ROC_AUC_Score:\",roc_auc_score(y_true, y_pred)*100)"
      ],
      "metadata": {
        "id": "d8fzWQcCqiQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting Data into Training Data and Testing Data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.30, random_state=1)\n"
      ],
      "metadata": {
        "id": "TAO1BYWIqiQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing Decision tree classification\n",
        "\n",
        "DT_object=tree.DecisionTreeClassifier(criterion='entropy',max_depth=4,max_leaf_nodes=10)\n",
        "DT_object.fit(X_train,Y_train)\n",
        "y_pred_dt=DT_object.predict(X_test)\n",
        "ass(Y_test,y_pred_dt)"
      ],
      "metadata": {
        "id": "WM3Ays-nqiQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_dt.shape"
      ],
      "metadata": {
        "id": "8Mz2toEiqiQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "import graphviz\n",
        "text_representation = tree.export_text(DT_object)\n",
        "print(text_representation)"
      ],
      "metadata": {
        "id": "-MhS3E9cqiQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features=['AGE_ABOVE65', 'DISEASE GROUPING 2', 'DISEASE GROUPING 3',\n",
        "       'DISEASE GROUPING 4', 'HTN', 'BIC_VENOUS_MEAN', 'CALCIUM_MEAN',\n",
        "       'CREATININ_MEAN', 'GLUCOSE_MEAN', 'INR_MEAN', 'LACTATE_MEAN',\n",
        "       'LEUKOCYTES_MEAN', 'LINFOCITOS_MEAN', 'NEUTROPHILES_MEAN',\n",
        "       'PC02_VENOUS_MEAN', 'PCR_MEAN', 'PLATELETS_MEAN', 'SAT02_VENOUS_MEAN',\n",
        "       'SODIUM_MEAN', 'UREA_MEAN', 'BLOODPRESSURE_DIASTOLIC_MEAN',\n",
        "       'RESPIRATORY_RATE_MEAN', 'TEMPERATURE_MEAN', 'OXYGEN_SATURATION_MEAN',\n",
        "       'BLOODPRESSURE_SISTOLIC_MIN', 'HEART_RATE_MIN', 'RESPIRATORY_RATE_MIN',\n",
        "       'TEMPERATURE_MIN', 'BLOODPRESSURE_DIASTOLIC_MAX',\n",
        "       'BLOODPRESSURE_SISTOLIC_MAX', 'HEART_RATE_MAX', 'OXYGEN_SATURATION_MAX',\n",
        "       'BLOODPRESSURE_DIASTOLIC_DIFF', 'BLOODPRESSURE_SISTOLIC_DIFF',\n",
        "       'HEART_RATE_DIFF', 'RESPIRATORY_RATE_DIFF', 'TEMPERATURE_DIFF',\n",
        "       'OXYGEN_SATURATION_DIFF', 'AGE_PERCENTIL_10th', 'AGE_PERCENTIL_20th',\n",
        "       'AGE_PERCENTIL_80th', 'AGE_PERCENTIL_90th']\n",
        "classes=['Non-ICU','ICU']\n",
        "dot_data = tree.export_graphviz(DT_object, out_file=None, \n",
        "                                feature_names=features,  \n",
        "                                class_names=classes,\n",
        "                                filled=True)\n",
        "graph = graphviz.Source(dot_data, format=\"png\") \n",
        "graph"
      ],
      "metadata": {
        "id": "z5cEpj8vqiQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters tuning Grid Search on Decision Tree\n",
        "\n",
        "param_grid = {'criterion':['entropy','gini'],'max_depth':np.arange(1,40),'max_leaf_nodes':np.arange(3,20),'random_state':[1,2]}\n",
        "GS_DT=GridSearchCV(DecisionTreeClassifier(), param_grid,cv=5)\n",
        "GS_DT.fit(X_train,Y_train)\n",
        "GS_DT.best_params_"
      ],
      "metadata": {
        "id": "o29n4LOvqiQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GS_DT.score(X_test,Y_test)"
      ],
      "metadata": {
        "id": "hESMfQMDqiQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score_dt = round(accuracy_score(y_pred_dt,Y_test)*100,2)\n",
        "print(\"The accuracy score achieved using Decision Tree is: \"+str(score_dt)+\" %\")"
      ],
      "metadata": {
        "id": "L0wN_CbPqiQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model complexity\n",
        "dt_train_score=[]\n",
        "dt_test_score=[]\n",
        "for i in np.arange(1, 30):\n",
        "  param_grid = {'criterion':['entropy','gini'],'max_depth': [i],'max_leaf_nodes':np.arange(3,20),'random_state':[1,2]}\n",
        "  GS_DT=GridSearchCV(DecisionTreeClassifier(), param_grid,cv=5)\n",
        "  GS_DT.fit(X_train,Y_train)\n",
        "  y_train_pred=GS_DT.predict(X_train)\n",
        "  y_pred=GS_DT.predict(X_test)\n",
        "  dt_train_score.append(log_loss(Y_train,y_train_pred))\n",
        "  dt_test_score.append(log_loss(Y_test,y_pred))"
      ],
      "metadata": {
        "id": "k4QGZlwyqiQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Decision Tree Classifier : Error vs Depth\")\n",
        "plt.xlabel(\"Depth\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.plot(np.arange(1,30),dt_train_score,label=\"Training Error\")\n",
        "plt.plot(np.arange(1,30),dt_test_score,label=\"Testing Error\")\n",
        "plt.legend()\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "a_fvds_2qiQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a Confusion matrix\n",
        "confusion_matrix_dt = confusion_matrix(Y_test,y_pred_dt)\n",
        "confusion_matrix_dt"
      ],
      "metadata": {
        "id": "_deLlbHkqiQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix_dt, annot=True,cmap='Blues',annot_kws={\"size\": 30})\n",
        "plt.show()\n",
        "\n",
        "print('True Positive:\\t{}'.format(confusion_matrix_dt[0,0]))\n",
        "print('True Negative:\\t{}'.format(confusion_matrix_dt[0,1]))\n",
        "print('False Positive:\\t{}'.format(confusion_matrix_dt[1,0]))\n",
        "print('False Negative:\\t{}'.format(confusion_matrix_dt[1,1]))"
      ],
      "metadata": {
        "id": "pTG2v63fqiQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Metrics\n",
        "from sklearn.metrics import classification_report\n",
        "matrix = classification_report(Y_test,y_pred_dt)\n",
        "print(\"classification_report: \\n\", matrix)\n"
      ],
      "metadata": {
        "id": "i7E-lAQiqiQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing K-Nearest Neighbour Classifier\n",
        "\n",
        "KNN_object=make_pipeline(KNeighborsClassifier(n_neighbors=25,p=1))\n",
        "KNN_object.fit(X_train,Y_train)\n",
        "y_pred_knn=KNN_object.predict(X_test)\n",
        "ass(Y_test,y_pred_knn)"
      ],
      "metadata": {
        "id": "fibEd-UoqiQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters tuning  Grid Search on K nearest neighbour\n",
        "\n",
        "param_grid = {'n_neighbors':[10,15,20,25,30,35,40],'leaf_size':np.arange(3,20),'p':[1,2]}\n",
        "GS_KNN=GridSearchCV(KNeighborsClassifier(), param_grid,cv=5)\n",
        "GS_KNN.fit(X_train,Y_train)\n",
        "GS_KNN.best_params_"
      ],
      "metadata": {
        "id": "fEED1XIHqiQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GS_KNN.score(X_test,Y_test)"
      ],
      "metadata": {
        "id": "tsLPe6dgqiQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score_knn = round(accuracy_score(y_pred_knn,Y_test)*100,2)\n",
        "print(\"The accuracy score achieved using K-Nearest Neighbour Classifier is: \"+str(score_knn)+\" %\")"
      ],
      "metadata": {
        "id": "2MrGUGJIqiQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model complexity\n",
        "knn_train_score=[]\n",
        "knn_test_score=[]\n",
        "for i in [10,15,20,25,30,35,40]:\n",
        "  param_grid = {'n_neighbors': [i],'leaf_size':np.arange(3,20),'p':[1,2]}\n",
        "  GS_KNN=GridSearchCV(KNeighborsClassifier(), param_grid,cv=5)\n",
        "  GS_KNN.fit(X_train,Y_train)\n",
        "  y_train_pred=GS_KNN.predict(X_train)\n",
        "  y_pred=GS_KNN.predict(X_test)\n",
        "  knn_train_score.append(log_loss(Y_train,y_train_pred))\n",
        "  knn_test_score.append(log_loss(Y_test,y_pred))"
      ],
      "metadata": {
        "id": "f_IUzguAqiQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"K-Neighbours Classifier: Error vs Number of Neighbors \")\n",
        "plt.xlabel(\"Number of Neighbors\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.plot([10,15,20,25,30,35,40],knn_train_score,label=\"Training Error\")\n",
        "plt.plot([10,15,20,25,30,35,40],knn_test_score,label=\"Testing Error\")\n",
        "plt.legend()\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "mNXfWpJwqiQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a Confusion matrix\n",
        "confusion_matrix_knn = confusion_matrix(Y_test,y_pred_knn)\n",
        "confusion_matrix_knn"
      ],
      "metadata": {
        "id": "CONDp8eIqiQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix_knn, annot=True,cmap='Blues',annot_kws={\"size\": 30})\n",
        "plt.show()\n",
        "\n",
        "print('True Positive:\\t{}'.format(confusion_matrix_knn[0,0]))\n",
        "print('True Negative:\\t{}'.format(confusion_matrix_knn[0,1]))\n",
        "print('False Positive:\\t{}'.format(confusion_matrix_knn[1,0]))\n",
        "print('False Negative:\\t{}'.format(confusion_matrix_knn[1,1]))"
      ],
      "metadata": {
        "id": "53HM2jgBqiQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Metrics\n",
        "from sklearn.metrics import classification_report\n",
        "matrix = classification_report(Y_test,y_pred_knn)\n",
        "print(\"classification_report: \\n\", matrix)\n"
      ],
      "metadata": {
        "id": "AcvV6qPyqiQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Classifier\n",
        "RF_object = RandomForestClassifier(criterion='gini',random_state=25,max_depth=8,bootstrap=True)\n",
        "RF_object.fit(X_train,Y_train)\n",
        "y_pred_rf=RF_object.predict(X_test)\n",
        "ass(Y_test,y_pred_rf)"
      ],
      "metadata": {
        "id": "CT-pWIjXqiQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper parameter tuning using Grid search on Random Forest Classifier\n",
        "\n",
        "param_grid = {'criterion':['gini','entropy'],'max_depth': [6],'random_state':[23]}\n",
        "GS_RF=GridSearchCV(RandomForestClassifier(), param_grid,cv=5)\n",
        "GS_RF.fit(X_train,Y_train)\n",
        "GS_RF.best_params_"
      ],
      "metadata": {
        "id": "QvRn9i2nqiQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GS_RF.score(X_test,Y_test)"
      ],
      "metadata": {
        "id": "yIcZPqDdqiQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score_rf = round(accuracy_score(y_pred_rf,Y_test)*100,2)\n",
        "print(\"The accuracy score achieved using Random Forest Classifier is: \"+str(score_rf)+\" %\")"
      ],
      "metadata": {
        "id": "3RpRH4Y_qiQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model complexity\n",
        "rf_train_score=[]\n",
        "rf_test_score=[]\n",
        "for i in np.arange(1, 30):\n",
        "  param_grid = {'criterion':['gini','entropy'],'max_depth': [i],'random_state':[23]}\n",
        "  GS_RF=GridSearchCV(RandomForestClassifier(), param_grid,cv=5)\n",
        "  GS_RF.fit(X_train,Y_train)\n",
        "  y_train_pred=GS_RF.predict(X_train)\n",
        "  y_pred=GS_RF.predict(X_test)\n",
        "  rf_train_score.append(log_loss(Y_train,y_train_pred))\n",
        "  rf_test_score.append(log_loss(Y_test,y_pred))"
      ],
      "metadata": {
        "id": "3rsX3tKnqiQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Random Forest Classifier : Error vs Max Depth\")\n",
        "plt.xlabel(\"Max Depth\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.plot(np.arange(1,30),rf_train_score,label=\"Training Error\")\n",
        "plt.plot(np.arange(1,30),rf_test_score,label=\"Testing Error\")\n",
        "plt.legend()\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "nN9-DpUsqiQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a Confusion matrix\n",
        "confusion_matrix_rf = confusion_matrix(Y_test,y_pred_rf)\n",
        "confusion_matrix_rf"
      ],
      "metadata": {
        "id": "yf5CGHoDqiQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix_rf, annot=True,cmap='Blues',annot_kws={\"size\": 30})\n",
        "plt.show()\n",
        "\n",
        "print('True Positive:\\t{}'.format(confusion_matrix_rf[0,0]))\n",
        "print('True Negative:\\t{}'.format(confusion_matrix_rf[0,1]))\n",
        "print('False Positive:\\t{}'.format(confusion_matrix_rf[1,0]))\n",
        "print('False Negative:\\t{}'.format(confusion_matrix_rf[1,1]))"
      ],
      "metadata": {
        "id": "yP_zZsH3qiQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Metrics\n",
        "from sklearn.metrics import classification_report\n",
        "matrix = classification_report(Y_test,y_pred_rf)\n",
        "print(\"classification_report: \\n\", matrix)\n"
      ],
      "metadata": {
        "id": "NELZlGXyqiQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = [score_dt,score_knn,score_rf]\n",
        "algorithms = [\"Decision Tree\",\"K-Nearest Neighbors\",\"Random Forest\"]    \n",
        "\n",
        "for i in range(len(algorithms)):\n",
        "    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")"
      ],
      "metadata": {
        "id": "k9tXXobIqiQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(20,10)})\n",
        "plt.xlabel(\"Algorithms\")\n",
        "plt.ylabel(\"Accuracy score\")\n",
        "\n",
        "sns.barplot(algorithms,scores)"
      ],
      "metadata": {
        "id": "iB2JLOFGqiQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}